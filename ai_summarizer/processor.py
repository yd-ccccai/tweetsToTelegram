import openai
from openai import AzureOpenAI, OpenAI
from config import Config

class AISummarizer:
    def __init__(self):
        self.setup_ai_client()

    def setup_ai_client(self):
        """æ ¹æ®é…ç½®åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        if Config.AI_PROVIDER == 'azure':
            self.client = AzureOpenAI(
                api_key=Config.AZURE_OPENAI_KEY,
                api_version=Config.AZURE_OPENAI_API_VERSION,
                azure_endpoint=Config.AZURE_OPENAI_ENDPOINT
            )
            self.model = Config.AZURE_DEPLOYMENT
            self.debug_print(f"åˆå§‹åŒ–Azure OpenAIå®¢æˆ·ç«¯ï¼š\n"
                          f"Endpoint: {Config.AZURE_OPENAI_ENDPOINT}\n"
                          f"API Version: {Config.AZURE_OPENAI_API_VERSION}\n"
                          f"Deployment: {Config.AZURE_DEPLOYMENT}")
        else:
            # OpenAIæˆ–å…¶ä»–ä¾›åº”å•†
            client_kwargs = {
                'api_key': Config.AI_API_KEY
            }
            if Config.AI_BASE_URL:
                client_kwargs['base_url'] = Config.AI_BASE_URL

            self.client = OpenAI(**client_kwargs)
            self.model = Config.AI_MODEL
            self.debug_print(f"åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼š\n"
                          f"Base URL: {Config.AI_BASE_URL or 'default'}\n"
                          f"Model: {self.model}")

    def debug_print(self, message):
        """è°ƒè¯•ä¿¡æ¯æ‰“å°"""
        print(f"[AI Debug] {message}")

    def summarize_tweets(self, tweets):
        try:
            if not tweets:
                return "æ²¡æœ‰æ‰¾åˆ°æœ€æ–°æ¨æ–‡ã€‚"
                
            # æŒ‰ç…§ order å­—æ®µæ’åºæ¨æ–‡
            sorted_tweets = sorted(tweets, key=lambda x: x.get('order', float('inf')))
            
            # å‡†å¤‡æ¨æ–‡å†…å®¹å’Œé“¾æ¥ï¼Œç¡®ä¿ä¸€ä¸€å¯¹åº”
            tweet_texts = []
            tweet_urls = []
            tweet_previews = []
            for tweet in sorted_tweets:
                # æå–æ¨æ–‡æ­£æ–‡ï¼Œå»é™¤ç”¨æˆ·åå’Œæ—¶é—´ä¿¡æ¯
                text = tweet['text']
                # æ£€æŸ¥æ˜¯å¦ä¸ºç½®é¡¶æ¨æ–‡
                is_pinned = tweet.get('pinned', False)
                # å¦‚æœæ˜¯ç½®é¡¶æ¨æ–‡ï¼Œæ·»åŠ æ ‡è¯†
                if is_pinned:
                    text = 'ğŸ“Œ ' + text
                # ç§»é™¤åŒ…å« @ çš„ç”¨æˆ·åä¿¡æ¯
                text = ' '.join([word for word in text.split() if not word.startswith('@')])
                # ç§»é™¤æ—¥æœŸä¿¡æ¯ï¼ˆé€šå¸¸åœ¨æ¨æ–‡æœ«å°¾ï¼Œæ ¼å¼å¦‚ Jan 28ï¼‰
                text = ' '.join([word for word in text.split() if not any(month in word for month in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])])
                
                tweet_texts.append(text)
                tweet_urls.append(tweet.get('url', ''))
                # ç”Ÿæˆæ¨æ–‡é¢„è§ˆï¼ˆå‰10ä¸ªå•è¯ï¼‰ï¼Œä¿ç•™ç½®é¡¶æ ‡è¯†
                words = text.split()
                preview = ' '.join(words[:10]) + '...' if len(words) > 10 else text
                tweet_previews.append(preview)
            
            text = "\n".join(tweet_texts)
            
            self.debug_print(f"å‡†å¤‡å‘é€è¯·æ±‚åˆ°{Config.AI_PROVIDER.upper()}")
            
            # è®¡ç®—æœ€å¤§é•¿åº¦é™åˆ¶
            max_tokens = 800
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒè¯­æ€»ç»“åŠ©æ‰‹ã€‚ä½ éœ€è¦æä¾›æ¸…æ™°ã€æ ¼å¼åŒ–çš„ä¸­è‹±æ–‡å¯¹ç…§æ€»ç»“ã€‚è¯·æå–æ¨æ–‡ä¸­æœ€é‡è¦çš„ä¿¡æ¯ç‚¹è¿›è¡Œæ€»ç»“ã€‚"},
                    {
                        "role": "user",
                        "content": f"""è¯·å¯¹ä»¥ä¸‹æ¨æ–‡å†…å®¹è¿›è¡ŒåŒè¯­æ€»ç»“ï¼š

1. æå–2-3ä¸ªæœ€é‡è¦çš„æ ¸å¿ƒä¿¡æ¯ç‚¹
2. æ¯ä¸ªä¿¡æ¯ç‚¹éƒ½éœ€è¦ä¸­è‹±æ–‡å¯¹ç…§
3. æ•°æ®æŒ‡æ ‡ç”¨`*åŠ ç²—*`çªå‡ºæ˜¾ç¤º

æ¨æ–‡å†…å®¹ï¼š
{text}

è¾“å‡ºæ ¼å¼ï¼š
ğŸ“Œ *æ ¸å¿ƒä¿¡æ¯æ¦‚è§ˆ* | *Key Information*
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1ï¸âƒ£ ä¸­æ–‡æ ¸å¿ƒä¿¡æ¯ç‚¹ä¸€
   ğŸ”¹ Key information point 1 in English

2ï¸âƒ£ ä¸­æ–‡æ ¸å¿ƒä¿¡æ¯ç‚¹äºŒ
   ğŸ”¹ Key information point 2 in English

3ï¸âƒ£ ä¸­æ–‡æ ¸å¿ƒä¿¡æ¯ç‚¹ä¸‰
   ğŸ”¹ Key information point 3 in English"""
                    }
                ],
                temperature=0.7,
                max_tokens=max_tokens
            )
            
            self.debug_print(f"æˆåŠŸæ”¶åˆ°{Config.AI_PROVIDER.upper()}å“åº”")
            content = response.choices[0].message.content
            
            # æ·»åŠ æ¨æ–‡é¢„è§ˆéƒ¨åˆ†
            preview_section = "\n\nğŸ“ *åŸå§‹æ¨æ–‡* | *Original Tweets*\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
            for i, (preview, url) in enumerate(zip(tweet_previews, tweet_urls), 1):
                preview_section += f"{i}. {preview}\n   ğŸ”— {url}\n\n"
            
            return content + preview_section

        except Exception as e:
            error_message = f"å¤„ç†æ¨æ–‡æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
            self.debug_print(error_message)
            return error_message

    def _generate_tweet_summary_template(self, urls):
        """ç”Ÿæˆæ¨æ–‡æ€»ç»“æ¨¡æ¿ï¼Œç¡®ä¿é“¾æ¥ä¸€ä¸€å¯¹åº”"""
        template = []
        for i, url in enumerate(urls, 1):
            template.append(f"{i}. ç¬¬{i}æ¡æ¨æ–‡ä¸­æ–‡æ€»ç»“\n   ğŸ”¹ Tweet {i} summary in English\n   ğŸ”— {url}\n")
        return "\n".join(template)
    
    def _split_content(self, content):
        """å°†å†…å®¹åˆ†æ®µï¼Œç¡®ä¿ä¸è¶…è¿‡Telegramæ¶ˆæ¯é•¿åº¦é™åˆ¶"""
        # æŒ‰ç…§æ®µè½åˆ†å‰²å†…å®¹
        parts = []
        current_part = ""
        
        # åˆ†å‰²å†…å®¹ä¸ºæ ¸å¿ƒä¿¡æ¯å’ŒåŸå§‹æ¨æ–‡ä¸¤éƒ¨åˆ†
        sections = content.split("ğŸ“ *åŸå§‹æ¨æ–‡* | *Original Tweets*")
        
        if len(sections) == 2:
            overview = sections[0].strip()
            tweets_section = "ğŸ“ *åŸå§‹æ¨æ–‡* | *Original Tweets*" + sections[1]
            
            # æ·»åŠ æ ¸å¿ƒä¿¡æ¯æ¦‚è§ˆä½œä¸ºç¬¬ä¸€éƒ¨åˆ†
            if len(overview) > 4000:
                # å¦‚æœæ¦‚è§ˆéƒ¨åˆ†è¿‡é•¿ï¼Œä¹Ÿéœ€è¦åˆ†æ®µ
                words = overview.split()
                for word in words:
                    if len(current_part) + len(word) + 1 > 3900:  # ç•™å‡ºç©ºé—´ç»™é¡µç å’Œå¯¼èˆªæ ‡è®°
                        parts.append(current_part.strip())
                        current_part = word
                    else:
                        current_part += " " + word if current_part else word
                if current_part:
                    parts.append(current_part.strip())
            else:
                parts.append(overview)
            
            # å¤„ç†æ¨æ–‡éƒ¨åˆ†
            current_part = ""
            tweets = tweets_section.split("\n\n")
            
            for tweet in tweets:
                if len(current_part) + len(tweet) + 2 > 3900:  # ç•™å‡ºç©ºé—´ç»™é¡µç å’Œå¯¼èˆªæ ‡è®°
                    if current_part:
                        parts.append(current_part.strip())
                    current_part = tweet
                else:
                    current_part += "\n\n" + tweet if current_part else tweet
            
            if current_part:
                parts.append(current_part.strip())
        else:
            # å¦‚æœæ— æ³•æ­£ç¡®åˆ†å‰²ï¼Œåˆ™æŒ‰ç…§å›ºå®šé•¿åº¦åˆ†å‰²
            words = content.split()
            for word in words:
                if len(current_part) + len(word) + 1 > 3900:  # ç•™å‡ºç©ºé—´ç»™é¡µç å’Œå¯¼èˆªæ ‡è®°
                    parts.append(current_part.strip())
                    current_part = word
                else:
                    current_part += " " + word if current_part else word
            
            if current_part:
                parts.append(current_part.strip())
        
        # ä¸ºåˆ†æ®µå†…å®¹æ·»åŠ é¡µç æ ‡è®°å’Œå¯¼èˆªæŒ‰é’®æ ‡è®°
        formatted_parts = []
        total_pages = len(parts)
        
        for i, part in enumerate(parts):
            page_info = f"\n\nğŸ“„ ç¬¬{i+1}é¡µ/å…±{total_pages}é¡µ"
            # æ·»åŠ ç‰¹æ®Šæ ‡è®°ç”¨äºTelegramå¤„ç†ç¨‹åºè¯†åˆ«å¹¶æ·»åŠ å¯¼èˆªæŒ‰é’®
            nav_marker = f"\n[NAV:{i+1}:{total_pages}]"
            formatted_parts.append(f"{part}{page_info}{nav_marker}")
        
        return formatted_parts
        
        # ä¸ºåˆ†æ®µå†…å®¹æ·»åŠ é¡µç æ ‡è®°
        return [f"{content}\n\nğŸ“„ ç¬¬{i+1}é¡µ/å…±{len(parts)}é¡µ" for i, content in enumerate(parts)]